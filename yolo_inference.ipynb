{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os \n",
    "import sys\n",
    "import math\n",
    "from tensorflow.python.keras.initializers import he_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.app.flags.DEFINE_integer('image_size', 416, \"Needs to provide same value as in training.\")\n",
    "tf.app.flags.DEFINE_string('checkpoint_dir', './checkpoint', 'the checkpoint dir')\n",
    "tf.app.flags.DEFINE_string('log_dir', './log', 'the logging dir')\n",
    "tf.app.flags.DEFINE_integer('num_classes', 37,'The num of classes need to predict')\n",
    "FLAGS = tf.app.flags.FLAGS\n",
    "tf.app.flags.DEFINE_string('f', '', 'kernel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bottle_neck(layer,is_training):\n",
    "    #------------bottleneck for yolo(darknet53)-----------\n",
    "    X = conv2d_bn_leak(layer,32,1,[3,3],is_training)\n",
    "    X = tf.pad(X,[[0,0],[1,0],[1,0],[0,0]])\n",
    "    X = conv2d_bn_leak(X,64,2,[3,3],is_training)\n",
    "    #------------\n",
    "    X = identity_block_2(X,[32,64],is_training)\n",
    "    #-------------\n",
    "    X = tf.pad(X,[[0,0],[1,0],[1,0],[0,0]])\n",
    "    X = conv2d_bn_leak(X,128,2,[3,3],is_training)\n",
    "    #-------------res*2\n",
    "    X = identity_block_2(X,[64,128],is_training)\n",
    "    X = identity_block_2(X,[64,128],is_training)\n",
    "    #-------------\n",
    "    X = tf.pad(X,[[0,0],[1,0],[1,0],[0,0]])\n",
    "    X = conv2d_bn_leak(X,256,2,[3,3],is_training)\n",
    "    #-------------resnet*8\n",
    "    for i in range(8):\n",
    "        X = identity_block_2(X,[128,256],is_training)\n",
    "    scale3 = X\n",
    "    #-------------conv\n",
    "    X = tf.pad(X,[[0,0],[1,0],[1,0],[0,0]])\n",
    "    X = conv2d_bn_leak(X,512,2,[3,3],is_training)\n",
    "    #-------------resnet*8\n",
    "    for i in range(8):\n",
    "        X = identity_block_2(X,[256,512],is_training) \n",
    "    scale2 = X\n",
    "    #------------conv\n",
    "    X = tf.pad(X,[[0,0],[1,0],[1,0],[0,0]])\n",
    "    X = conv2d_bn_leak(X,1024,2,[3,3],is_training)\n",
    "    #-----------resnet*4\n",
    "    for i in range(4):\n",
    "        X = identity_block_2(X,[512,1024],is_training) \n",
    "    #-----------avg-pooling\n",
    "#     X = tf.layers.average_pooling2d(X,[2,2],strides=1)\n",
    "    scale1 = X\n",
    "    return X,scale1,scale2,scale3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity_block_2(layer,layer_depth,is_training):\n",
    "    depth1,depth2 = layer_depth\n",
    "    shortcut = layer\n",
    "    conv_layer1 = tf.layers.conv2d(layer, depth1, [1,1], 1, 'same', use_bias=True,kernel_initializer=he_normal(seed=0.01),activation=None,kernel_regularizer=tf.contrib.layers.l2_regularizer(0.01))\n",
    "    conv_layer1_bn = tf.layers.batch_normalization(conv_layer1, training=is_training)\n",
    "    conv_layer1_out = tf.nn.relu(conv_layer1_bn)\n",
    "    \n",
    "    conv_layer2 = tf.layers.conv2d(conv_layer1_out, depth2, [3,3], 1, 'same', use_bias=True,kernel_initializer=he_normal(seed=0.01),activation=None,kernel_regularizer=tf.contrib.layers.l2_regularizer(0.01))\n",
    "    conv_layer2_bn = tf.layers.batch_normalization(conv_layer2, training=is_training)\n",
    "\n",
    "    conv_add = shortcut+conv_layer2_bn\n",
    "    conv_layer2_out = tf.nn.leaky_relu(conv_add,alpha=0.1)\n",
    "\n",
    "    return conv_layer2_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d_bn_leak(layer,depth,stride,kernel_size,is_training):\n",
    "    if stride ==1:\n",
    "        padding ='same'\n",
    "    else:\n",
    "        padding ='valid'\n",
    "    X = tf.layers.conv2d(inputs=layer,filters=depth,kernel_size=kernel_size,strides=stride,padding=padding,use_bias=True,kernel_initializer=he_normal(seed=0.01),activation=None,kernel_regularizer=tf.contrib.layers.l2_regularizer(5e-4))\n",
    "    X = tf.layers.batch_normalization(X,training=is_training)\n",
    "    X = tf.nn.leaky_relu(X,alpha=0.1)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale(X,scale,depth,num_anchors,num_class,is_training):\n",
    "    if(depth!=512):\n",
    "        X = conv2d_bn_leak(X,depth,1,[3,3],is_training)\n",
    "        X = tf.image.resize_nearest_neighbor(X,(X.shape[1]*2,X.shape[2]*2))\n",
    "#         print(scale2.shape)\n",
    "#         print(X.shape)\n",
    "        X = tf.concat([X,scale],axis=3)\n",
    "\n",
    "    #scale1 13*13\n",
    "    X = conv2d_bn_leak(X,depth,1,[1,1],is_training)\n",
    "    X = conv2d_bn_leak(X,depth*2,1,[3,3],is_training)\n",
    "    X = conv2d_bn_leak(X,depth,1,[1,1],is_training)\n",
    "    X = conv2d_bn_leak(X,depth*2,1,[3,3],is_training)\n",
    "    X = conv2d_bn_leak(X,depth,1,[1,1],is_training)\n",
    "\n",
    "    scale = conv2d_bn_leak(scale,depth*2,1,[3,3],is_training)\n",
    "    scale = tf.layers.conv2d(scale, num_anchors*(num_class+5), [1,1], 1, 'same', use_bias=True,kernel_initializer=he_normal(seed=0.01),activation=None,kernel_regularizer=tf.contrib.layers.l2_regularizer(0.01))\n",
    "    return X,scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yolo_head_2(net_out, anchors, n_class, input_shape):\n",
    "    boxes = list()\n",
    "    box_scores = list()\n",
    "\n",
    "    cellbase_x = tf.to_float(tf.reshape(tf.tile(tf.range(52), [52]), (1, 52, 52, 1, 1)))\n",
    "    cellbase_y = tf.transpose(cellbase_x, (0, 2, 1, 3, 4))\n",
    "    cellbase_grid = tf.tile(tf.concat([cellbase_x, cellbase_y], -1), [1, 1, 1, 3, 1])\n",
    "    anchors = tf.constant(anchors, dtype='float', shape=[1, 1, 1, 9, 2])\n",
    "    \n",
    "    temp_box_confidence = []\n",
    "    temp_box_class_probs = []\n",
    "    temp_box_wh = []\n",
    "    temp_box_yx = []\n",
    "    for i in range(3):  # 52 26 13\n",
    "        anchor = anchors[..., 3 * i:3 * (i + 1), :]\n",
    "        # feats = model.output[i]\n",
    "        feats = net_out[i]\n",
    "\n",
    "        grid_w = tf.shape(feats)[1]  # 13\n",
    "        grid_h = tf.shape(feats)[2]  # 13\n",
    "        grid_factor = tf.reshape(tf.cast([grid_w, grid_h], tf.float32), [1, 1, 1, 1, 2])\n",
    "\n",
    "        feats = tf.reshape(feats, [-1, grid_w, grid_h, 3, n_class + 5])\n",
    "\n",
    "        # Adjust preditions to each spatial grid point and anchor size.\n",
    "        box_xy = (tf.sigmoid(feats[..., :2]) + cellbase_grid[:, :grid_w, :grid_h, :, :]) / tf.cast(grid_factor[::-1],\n",
    "                                                                                                   'float32')\n",
    "        box_wh = tf.exp(feats[..., 2:4]) * anchor / tf.cast(input_shape[::-1], 'float32')\n",
    "        box_confidence = tf.sigmoid(feats[..., 4:5])\n",
    "        box_class_probs = tf.sigmoid(feats[..., 5:])\n",
    "\n",
    "        box_yx = box_xy[..., ::-1]\n",
    "        box_hw = box_wh[..., ::-1]\n",
    "#         box_yx = (box_yx - offset) * scale\n",
    "#         box_hw *= scale\n",
    "        box_mins = box_yx - (box_hw / 2.)\n",
    "        box_maxes = box_yx + (box_hw / 2.)\n",
    "        _boxes = tf.concat([\n",
    "            box_mins[..., 0:1],  # y_min\n",
    "            box_mins[..., 1:2],  # x_min\n",
    "            box_maxes[..., 0:1],  # y_max\n",
    "            box_maxes[..., 1:2]  # x_max\n",
    "        ], axis=-1)\n",
    "\n",
    "        # Scale boxes back to (416,416) image shape.\n",
    "        _boxes *= tf.concat([tf.cast((416,416), 'float32'), tf.cast((416,416), 'float32')], axis=-1)\n",
    "        _boxes = tf.reshape(_boxes, [-1, 4])\n",
    "\n",
    "        _box_scores = box_confidence * box_class_probs\n",
    "        _box_scores = tf.reshape(_box_scores, [-1, n_class])\n",
    "        boxes.append(_boxes)\n",
    "        box_scores.append(_box_scores)\n",
    "        \n",
    "    boxes = tf.concat(boxes, axis=0)\n",
    "    box_scores = tf.concat(box_scores, axis=0)\n",
    "\n",
    "    mask = box_scores >= 0.5\n",
    "    max_num_boxes = tf.constant(20, dtype='int32')\n",
    "\n",
    "    boxes_ = []\n",
    "    scores_ = []\n",
    "    classes_ = []\n",
    "    for c in range(n_class):\n",
    "        class_boxes = tf.boolean_mask(boxes, mask[:, c])\n",
    "        class_box_scores = tf.boolean_mask(box_scores[:, c], mask[:, c])\n",
    "        nms_index = tf.image.non_max_suppression(\n",
    "            class_boxes, class_box_scores, max_num_boxes, iou_threshold=0.5)\n",
    "        class_boxes = tf.gather(class_boxes, nms_index)\n",
    "        class_box_scores = tf.gather(class_box_scores, nms_index)\n",
    "        classes = tf.ones_like(class_box_scores, 'int32') * c\n",
    "        boxes_.append(class_boxes)\n",
    "        scores_.append(class_box_scores)\n",
    "        classes_.append(classes)\n",
    "    boxes_ = tf.concat(boxes_, axis=0)\n",
    "    scores_ = tf.concat(scores_, axis=0)\n",
    "    classes_ = tf.concat(classes_, axis=0)\n",
    "    return boxes_,scores_,classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchors = []\n",
    "with open('./data/yolo_anchors.txt','r') as f:\n",
    "    for line in f.readlines():\n",
    "        anchors.append(line.strip('\\n'))\n",
    "temp = anchors[0].split(', ')\n",
    "temp_list = []\n",
    "for i in temp:\n",
    "    temp_list.append(i.split(','))\n",
    "temp_list = np.array(temp_list)\n",
    "anchors = temp_list.astype(np.float32)\n",
    "num_anchors = len(anchors)//3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.placeholder(tf.float32, [None, 416, 416, 3])\n",
    "# keep_prob = tf.placeholder('float')\n",
    "is_training = tf.placeholder(tf.bool)\n",
    "layer = inputs \n",
    "\n",
    "#bottle neck\n",
    "X,scale1,scale2,scale3 = bottle_neck(layer,is_training)\n",
    "# print(X.shape)\n",
    "#scale1 13*13\n",
    "X,scale1 = scale(X,scale1,512,num_anchors,FLAGS.num_classes,is_training)\n",
    "\n",
    "#scale2 26*26\n",
    "X,scale2 = scale(X,scale2,256,num_anchors,FLAGS.num_classes,is_training)\n",
    "\n",
    "#scale 52*52\n",
    "X,scale3 = scale(X,scale3,128,num_anchors,FLAGS.num_classes,is_training)\n",
    "\n",
    "scale1 = tf.reshape(scale1,(-1,13,13,num_anchors,FLAGS.num_classes+5))\n",
    "scale2 = tf.reshape(scale2,(-1,26,26,num_anchors,FLAGS.num_classes+5))\n",
    "scale3 = tf.reshape(scale3,(-1,52,52,num_anchors,FLAGS.num_classes+5))\n",
    "y_pred = [scale3,scale2,scale1]\n",
    "# anchors = [25.0,39.0,35.0,87.0,61.0,52.0,67.0,134.0,121.0,96.0,122.0,205.0,207.0,287.0,262.0,148.0,373.0,300.0]\n",
    "# boxes_,scores_,classes_ = yolo_head(y_pred[0], anchors[6:12], num_class, (416,416),calc_loss=False)\n",
    "boxes_,scores_,classes_ = yolo_head_2(y_pred, anchors, FLAGS.num_classes, (FLAGS.image_size,FLAGS.image_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_path_and_annotation(file_path):\n",
    "    annotation = []\n",
    "    img_path = []\n",
    "    line_list = []\n",
    "    with open(file_path,'r') as f:\n",
    "        for line in f:\n",
    "            temp=[]\n",
    "            line = line.strip('\\n')\n",
    "            line_list.append(line)\n",
    "        random.shuffle(line_list)\n",
    "\n",
    "    for i in line_list:\n",
    "        line = i.split(' ')\n",
    "        img_path.append(line[0])\n",
    "        temp = []\n",
    "        temp_inner= []\n",
    "        for j in range(1,len(line)):\n",
    "            temp.append(line[j].split(','))\n",
    "        annotation.append(temp)\n",
    "    return img_path,annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path,annotation = get_path_and_annotation('./data/test_ocr.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "corresponding_dict = {1:'1',2:'2',3:'3',4:'4',5:'5',6:'6',7:'7',\\\n",
    "                      8:'8',9:'9',0:'0',10:'A',11:'B',12:'C',\\\n",
    "                     13:'D',14:'E',15:'F',16:'G',17:'H',18:'I',\\\n",
    "                      19:'J',20:'K',21:'L',22:'M',23:'N',24:'O',25:'P',\\\n",
    "                      26:'Q',27:'R',28:'S',29:'T',30:'U',31:'V',32:'W',33:'X',34:'Y',35:'Z',36:'-'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "box_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "saver = tf.train.Saver()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "ckpt = tf.train.latest_checkpoint(FLAGS.checkpoint_dir)\n",
    "if ckpt:\n",
    "    saver.restore(sess,ckpt)\n",
    "    print('restore from the checkpoint {0}'.format(ckpt))\n",
    "# [b,s,c,temp_feat,box_confidence,class_probs,box_wh,box_yx] = sess.run([boxes_,scores_,classes_,y_pred,temp_box_confidence,temp_box_class_probs,temp_box_wh,temp_box_yx],feed_dict={inputs:image,is_training: False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for temp_count in range(50):\n",
    "    image = cv2.imread(img_path[temp_count])\n",
    "    image = image[:,:,::-1]\n",
    "    image_temp = image.astype(np.float32)\n",
    "    image_temp = cv2.resize(image_temp,(FLAGS.image_size,FLAGS.image_size))\n",
    "    image_temp = np.expand_dims(image_temp,axis=0)\n",
    "    import time\n",
    "    start = time.time()\n",
    "    [b,s,c,temp_feat] = sess.run([boxes_,scores_,classes_,y_pred],feed_dict={inputs:image_temp,is_training: False})\n",
    "    elapsed = time.time()-start\n",
    "    print(elapsed)\n",
    "    box_class = [corresponding_dict[i] for i in c]\n",
    "    \n",
    "    #convert bboxes from (416,416) to (1280,1024)\n",
    "    y_ratio = 416/1024\n",
    "    x_ratio = 416/1280\n",
    "    b_transformed = np.zeros_like(b)\n",
    "    b_transformed[...,0] = (b[...,0]/y_ratio)\n",
    "    b_transformed[...,1] = (b[...,1]/x_ratio)\n",
    "    b_transformed[...,2] = (b[...,2]/y_ratio)\n",
    "    b_transformed[...,3] = (b[...,3]/x_ratio)\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(20,20))\n",
    "    plt.hlines(b_transformed[...,0],b_transformed[...,1],b_transformed[...,3],colors='r')\n",
    "    plt.hlines(b_transformed[...,2],b_transformed[...,1],b_transformed[...,3],colors='r')\n",
    "    plt.vlines(b_transformed[...,1],b_transformed[...,0],b_transformed[...,2],colors='r')\n",
    "    plt.vlines(b_transformed[...,3],b_transformed[...,0],b_transformed[...,2],colors='r')\n",
    "    for i in range(b_transformed.shape[0]):\n",
    "        plt.text((b_transformed[i][3]+b_transformed[i][1])/2-10,((b_transformed[i][2]+b_transformed[i][0])/2)-30,box_class[i],fontsize=50,color='r')\n",
    "    plt.imshow(image)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorlayer as tl\n",
    "import xml.etree.ElementTree as ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('./data/JPEGImages/1.jpg')\n",
    "img = img[:,:,::-1]\n",
    "tree = ET.ElementTree(file = './data/Annotations/1.xml')\n",
    "xmin = []\n",
    "xmax = []\n",
    "ymin = []\n",
    "ymax = []\n",
    "temp_class = []\n",
    "root = tree.getroot()\n",
    "for i in root:\n",
    "    if((i.find('name')!=None)):\n",
    "        temp_class.append(i.find('name').text)\n",
    "        xmin.append(int(i.find('bndbox').find('xmin').text))\n",
    "        xmax.append(int(i.find('bndbox').find('xmax').text))\n",
    "        ymin.append(int(i.find('bndbox').find('ymin').text))\n",
    "        ymax.append(int(i.find('bndbox').find('ymax').text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords_original = []\n",
    "for i in range(len(xmin)):\n",
    "    coords_original.append([xmin[i],ymin[i],xmax[i],ymax[i]])\n",
    "coords = []\n",
    "xywh_t = []\n",
    "for i in coords_original:\n",
    "    coords.append(tl.prepro.obj_box_coord_upleft_butright_to_centroid(i))\n",
    "im_flip, coords = tl.prepro.obj_box_left_right_flip(img,coords,is_rescale=False,is_center=True)\n",
    "for i in range(len(coords)):\n",
    "    xywh_t.append(tl.prepro.obj_box_coord_centroid_to_upleft_butright(coords[i]))\n",
    "xywh_t = np.array(xywh_t)\n",
    "xywh_t = xywh_t.astype(np.int32)\n",
    "show_box(xywh_t,im_flip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coords = tl.prepro.obj_box_coords_rescale(coords=coords, shape=[1280, 1024])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xywh_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xywh_t = np.squeeze(xywh_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xywh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_box(b_transformed,image):\n",
    "    plt.figure(figsize=(20,20))\n",
    "    plt.hlines(b_transformed[...,1],b_transformed[...,0],b_transformed[...,2],colors='r')\n",
    "    plt.hlines(b_transformed[...,3],b_transformed[...,0],b_transformed[...,2],colors='r')\n",
    "    plt.vlines(b_transformed[...,0],b_transformed[...,1],b_transformed[...,3],colors='r')\n",
    "    plt.vlines(b_transformed[...,2],b_transformed[...,1],b_transformed[...,3],colors='r')\n",
    "    plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_box(np.array(xywh),img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'/home/xinje/Desktop/'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
